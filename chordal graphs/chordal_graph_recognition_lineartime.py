# -*- coding: utf-8 -*-
"""chordal_graph_recognition_LinearTime.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hHT6MaxAKEcXmsSjI1C4oZhs4EjKEyln

# **Author: Shekoofeh Nekooei Rizi**


This program determines if an input graph is chordal, in linear time with respect to
the input graph size (number of vertices + number of edges).


I implement the classic algorithm from
"Algorithmic Aspects of Vertex Elimination on Graphs" by Rose, Tarjan, and Lueker.


The process starts by computing a **Lexicographical Breadth First Search (LexBFS)** ordering of vertices.

[I use **partition refinement** technique, which I learned from:
"A Simple Linear Time Algorithm for Cographs Recognition" by Bretscher, Corneil, Habib, and Paul.]

Next, the program checks if the reverse of this sequence forms a **perfect elimination ordering**  -- a property unique to chordal graphs.


Achieving linear-time performance requires a careful and creative approach, especially in the partition refinement method.  
The method, as often described in the literature, results in quadratic overall time due to repeated full scans through partitions.

To avoid this, instead of iterating over all partitions and their vertices during each refinement step, I iterate over the neighbors of the pivot.  
This ensures that the total cost across all iterations is proportional to the sum of vertex degrees, and therefore linear in the number of edges.


Moreover, to achieve linear time performance in this algorithm, (in LexBFS and partition refinement),
each vertex movement and its consequent partition update/refinement must be done in constant time.

This is possible through operations on ` particular data structures `, using ` pointers ` and ` doubly linked lists `.

So, the data structure implementation isn't quite straightforward,
but in return the program achieves the algorithm's expected linear time complexity.

With that being said, I tried to keep the code simple and readable as much as possible.


As a final note, to keep the code simple and the algorithm easier to understand, I use Python's built-in `min()` function in the main section of the program .

I test the correctness and performance of the program using both small and big graphs.



Lastly, I just want to say â€” It is fascinating to see that the program reaches the expected results fast, even for huge graphs with sizes over ten million. ðŸ˜ƒ
"""

################################
# This is a helper class, to represent each vertex of the input graph as a pointer object in a doubly linked list.

class Vertex_Pointer:
    """
    A node object in a doubly linked list representing a vertex in a graph.

    Attributes:
        value: label of the vertex
        next:  A reference to the next vertex in the list
        prev:  A reference to the previous vertex in the list.
    """

    def __init__(self, value):
        self.value = value
        self.next = None
        self.prev = None

################################
# This is a helper class, to represent each partition of vertex pointers in a doubly linked list.

class Partitions_Pointer:
    """
    Each partition maintains a list of vertices (as Vertex_Pointer objects), and pointers (prev and next)
    to adjacent partitions in the overall partition list.

    This data structure supports efficient insertion and removal of vertices.

    Attributes:
        next: Reference to the next partition in the partition list.
        prev: Reference to the previous part.
        head: The first vertex pointer in this partition.
        tail: The last vertex pointer in this partition.
        size: The number of vertices (or equivalently vertex pointers) currently in the partition.

    """
    def __init__(self):
        self.next = None
        self.prev = None

        self.head = None
        self.tail = None

        self.size = 0

    def add_v_pointer(self, vertex_ptr):
        """
        Adds a vertex pointer to the end (tail) of the partition.
        It runs in constant time.

        Input:
            vertex_ptr (Vertex_Pointer): The vertex pointer to be added.
        """
        self.size += 1

        if self.tail:
            self.tail.next = vertex_ptr
            vertex_ptr.prev = self.tail
            vertex_ptr.next = None
            self.tail = vertex_ptr

        else:
            vertex_ptr.prev = None
            vertex_ptr.next = None
            self.head = self.tail = vertex_ptr

    def remove_v_pointer(self, vertex_ptr):
        """
        Removes a vertex pointer from the partition.
        It handles all cases:
         - vertex pointer is in the middle of the list
         - vertex pointer is at the tail
         - vertex pointer is at the head
         - vertex is alone

        It runs in constant time.

        Input:
            vertex_ptr (Vertex_Pointer): The vertex pointer to be removed.
        """
        self.size -= 1

        if vertex_ptr.prev and vertex_ptr.next:
            vertex_ptr.prev.next = vertex_ptr.next
            vertex_ptr.next.prev = vertex_ptr.prev

        elif vertex_ptr.prev:
            vertex_ptr.prev.next = None
            self.tail = vertex_ptr.prev

        elif vertex_ptr.next:
            vertex_ptr.next.prev = None
            self.head = vertex_ptr.next

        else:
            self.head = None
            self.tail = None

        vertex_ptr.prev = vertex_ptr.next = None

def LexBFS(graph):
    """
    Computes a Lexicographical Breadth-First Search (LexBFS) ordering of the vertices of the input graph in linear time.

    This implementation uses partition refinement with doubly linked lists to ensure linear time complexity.

    The data structure uses two layers of doubly linked lists:
    - vertex pointers, linked together within each partition
    - partition pointers, which are themselves linked to one another


    The key idea is to update partitions efficiently as vertices are visited:
    - At each step, the leftmost unvisited vertex is chosen as the pivot.
    - Its neighbors are moved into a new partition just before their current ones.
    These updates / refinements maintain the lexicographic property of the ordering.

    Input:
        graph (dict): An undirected graph represented as an adjacency list.
        Keys are vertices and values are lists of neighbors.

        For example, graph = {v1: [v2], v2: [v1]} represents a graph which is a single edge between vertices v1 and v2.

        Vertices can be any hashable type (e.g., int, str).

    Output:
        list: A list of all vertices of graph in LexBFS order.
    """
    if not graph:
        return []

    vertex_to_pointer_map = {}
    initial_partition = Partitions_Pointer()
    partition_tag = {}

    for v in graph:
        v_ptr = Vertex_Pointer(v)
        vertex_to_pointer_map[v] = v_ptr
        initial_partition.add_v_pointer(v_ptr)
        partition_tag[v] = initial_partition

    partitions_head = initial_partition
    partitions_tail = initial_partition

    def partition_refinement(v):
        """
        Updates partitions based on neighbors of vertex 'v'.

        Moves each neighbor to a new partition before its current one, preserving LexBFS ordering.
        Updates links and removes empty parts.

        """
        nonlocal partitions_head

        splitted = {}

        for neighbor in graph[v]:
            if neighbor not in partition_tag:
                continue

            part = partition_tag[neighbor]
            neighbor_ptr = vertex_to_pointer_map[neighbor]

            if part in splitted:
                v_neighbor_part = splitted[part]
            else:
                v_neighbor_part = Partitions_Pointer()
                splitted[part] = v_neighbor_part

                if partitions_head == part:
                    partitions_head = v_neighbor_part

                v_neighbor_part.next = part
                v_neighbor_part.prev = part.prev

                if part.prev:
                    part.prev.next = v_neighbor_part
                else:
                    partitions_head = v_neighbor_part

                part.prev = v_neighbor_part

            part.remove_v_pointer(neighbor_ptr)
            v_neighbor_part.add_v_pointer(neighbor_ptr)

            partition_tag[neighbor] = v_neighbor_part

            if part.size == 0:
                if part.next:
                    part.next.prev = part.prev
                if part.prev:
                    part.prev.next = part.next

                part.next = None
                part.prev = None


    order = []

    for _ in range(len(graph)):
        while partitions_head and partitions_head.head is None:
            partitions_head = partitions_head.next

        if not partitions_head:
            break

        pivot_ptr = partitions_head.head
        pivot_vertex = pivot_ptr.value
        order.append(pivot_vertex)

        del partition_tag[pivot_vertex]

        partitions_head.remove_v_pointer(pivot_ptr)

        partition_refinement(pivot_vertex)

    return order

def is_chordal(graph):
    """
    Determines if the input graph is chordal using the LexBFS and PEO test.

    A graph is chordal if and only if
    the reverse of some Lexicographical Breadth First Search (LexBFS) order
    is a perfect elimination ordering (PEO).

    Here a LexBFS ordering of vertices is generated. Then the program checks if the reverse of this sequence is POE.

    Input:
        graph (dict): An adjacency list representation of an undirected graph.
        Each key is a vertex, and its value is a list of neighboring vertices. (dict of vertex -> list of neighbors)

    Output:
        bool: True if the graph is chordal, False otherwise.
    """

    LexBFS_order = LexBFS(graph)
    reverse_LexBFS_order = list(reversed(LexBFS_order))

    position = {vertex: index for index, vertex in enumerate(reverse_LexBFS_order)}

    for v in reverse_LexBFS_order:
        forward_neighbors = [neighbor for neighbor in graph[v] if position[v] < position[neighbor]]
        if not forward_neighbors:
            continue

        leftmost_neighbor = min(forward_neighbors, key = lambda x: position[x])

        for neighbor in forward_neighbors:
            if not (neighbor in graph[leftmost_neighbor] or leftmost_neighbor == neighbor):
                return False

    return True

"""## **Sample tests**

**Small samples**
"""

c3 = {'a': ['b', 'c'], 'b': ['a', 'c'], 'c': ['a', 'b']}
is_chordal(c3)

c4 = {1: [2, 4], 2: [1, 3], 3: [2, 4], 4: [1, 3]}
is_chordal(c4)

p5 = {'a':['b'], 'b': ['a', 'c'], 'c': ['b', 'd'], 'd': ['c', 'e'], 'e': ['d'] }
is_chordal(p5)

# I came up with this graph during my masterâ€™s research at SFU.

g = {'A': ['B', 'C', 'D', 'E', 'G'],
     'B': ['A', 'C', 'D', 'E', 'F'],
     'C': ['A', 'B', 'D', 'F'],
     'D': ['A', 'B', 'C', 'G'],
     'E': ['A', 'B'],
     'F': ['B', 'C'],
     'G': ['A', 'D']}

is_chordal(g)

# Martin Golumbic discussed this graph in a lecture available on YouTube.

MG = {'a': ['b', 'c', 'd'],
     'b':['a', 'd'],
     'c':['a', 'e'],
     'd':['a', 'b', 'f'],
     'e':['c'],
     'f': ['d']}

is_chordal(MG)

g = {'1': ['0', '2', '5'], '2': ['0', '1', '3'], '3': ['0', '2', '4'], '4': ['0', '3', '5'], '5': ['0', '4', '1'], '0': ['1', '2', '3', '4', '5'], }

is_chordal(g)

g = {1:[2], 2:[1], 3:[], 4:[5, 7], 5:[4, 6], 6:[5, 7], 7:[4, 6]}
is_chordal(g)

twoc3 = {'a': ['b', 'c'], 'b': ['a', 'c'], 'c': ['a', 'b'], 'A': ['B', 'C'], 'B': ['A', 'C'], 'C': ['A', 'B']}
is_chordal(twoc3)

# Donald Knuth disussed this graph in a talk, available on youtube.

DN = {
    1: [2, 3],
    2: [1, 3, 4, 5],
    3: [1, 2, 4, 7],
    4: [2, 3, 5, 6, 7, 8],
    5: [2, 4, 8, 9],
    6: [4, 7, 8, 10],
    7: [3, 4, 6, 10],
    8: [4, 5, 6, 9],
    9: [5, 8],
    10: [6, 7]
}
is_chordal(DN)

feder_graph_7 = {1: [3, 4, 5, 6],
                 2: [3],
                 3: [2, 4],
                 4: [3, 5],
                 5: [4, 6],
                 6: [5, 7],
                 7: [6]}

is_chordal(feder_graph_7)

"""
**Big Samples**


In this section, I provide larger graph samples to test and see the performance of the program.


To see the performance of the program, here I use two sets of graph structures.

First, I define a specific graph structure and call it Feder_graph($n$).

This graph consists of a path of n-1 vertices and an additional vertex that is connected
to all vertices of this path except the first and the last ones.

By choosing a large input n, we can generate sizable graphs with n vertices and 2n-5 edges.

We know that graphs with this structure are chordal. I studied this structure in my thesis: "Matrix partition of chordal graphs"
and also in "Obstructions to partitions of chordal graphs", and "Partitioning chordal graphs".

Next, I test the program with Mycielski graphs.

Mycielskians are clearly not chordal. This makes them a useful counterexample to verify the correctness of the algorithm.

These graphs grow exponentially through iterations of the Mycielski construction.


It is worth noting that the level-16 Mycielski graph has a size of over 16 million (around 17 million edges and vertices).
This program correctly  identifies it as not chordal in under a minute (in my experiments).
Similarly, Feder_graph(10**7) is also very huge, with almost 30 million vertices and edges in total.
The program successfully recognizes it as a chordal graph in around  1 - 1.5  minutes."""

def Feder_graph(n):
    """
    This function generates a graph consists of a path of n-1 vertices and
    an additional vertex that is connected to all vertices of this path except the first and the last ones.
    """
    graph = {}
    graph[1] = [vertex for vertex in range(3, n)]
    graph[2] = [3]
    graph[n] = [n-1]
    for v in range(3, n):
        graph[v] = [1, v-1, v+1]

    return graph

import time

def test_Feder_graph(n):
    """
    It makes a Feder graph with n vertices, runs the is_chordal function on it,
    and prints a summary table including:

    - Whether the graph is chordal
    - Number of vertices
    - Number of edges
    - Size of the graph (vertices + edges)
    - Execution time of the  is_chordal function in seconds

    Input:
        n (int): Number of vertices for the Feder graph.
    """

    graph = Feder_graph(n)

    num_vertices = n
    num_edges = 2 * n - 5
    graph_size = num_vertices + num_edges

    start = time.time()
    result = is_chordal(graph)
    finish = time.time()
    running_time = finish - start

    # Print table
    print(f"\n{'Is Chordal':<12} {'Vertices':<12} {'Edges':<12} {'Size':<12} {'Time (s)':<10}")
    print(f"{'-'*60}")
    print(f"{str(result):<12} {num_vertices:<12} {num_edges:<12} {graph_size:<12} {running_time:.6f}")

Feder_graph(10)

is_chordal(Feder_graph(10))

test_Feder_graph(10**3)

test_Feder_graph(10**4)

test_Feder_graph(10**5)

test_Feder_graph(10**6)

test_Feder_graph(10**7)

import time
from networkx.generators.mycielski import mycielski_graph

def test_Mycielski(n):
    """
    Generates a Mycielski graph after n iterations of the construction method.
    Then, runs the is_chordal function on it, and prints a summary table including:

    - Whether the graph is chordal
    - Number of vertices
    - Number of edges
    - Size of the graph (vertices + edges)
    - Execution time of the  is_chordal function in seconds

    Input:
        n (int): Number of levels the Mycielski operation is performed.
    """

    M = mycielski_graph(n)
    M_valid_format = {node: list(M[node]) for node in M.nodes()}
    num_vertices = M.number_of_nodes()
    num_edges = M.number_of_edges()
    graph_size = num_vertices + num_edges

    start = time.time()
    result = is_chordal(M_valid_format)
    finish = time.time()
    running_time = finish - start

    # Print table
    print(f"\n{'Is Chordal':<12} {'Vertices':<12} {'Edges':<12} {'Size':<12} {'Time (s)':<10}")
    print(f"{'-'*60}")
    print(f"{str(result):<12} {num_vertices:<12} {num_edges:<12} {graph_size:<12} {running_time:.6f}")

M5 = mycielski_graph(5)
print("\nLevel five Mycielski ", M5, "\n")
Mycielski_5_valid_format = {node: list(M5[node]) for node in M5.nodes()}
Mycielski_5_valid_format

print("Is Mycielsky graph, level five, chordal?\n" )
is_chordal(Mycielski_5_valid_format)

test_Mycielski(13)

test_Mycielski(14)

test_Mycielski(15)

test_Mycielski(16)