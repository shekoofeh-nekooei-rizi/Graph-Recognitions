# -*- coding: utf-8 -*-
"""interval_graph_recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fCUSGuw5Ovnua73nXKzq9JjDKhH3TN3H

# **Author: Shekoofeh Nekooei Rizi**


This program determines if an input graph is an interval graph or not.

I implement the algorithm discussed in the paper "The LBFS structure and recognition of interval graphs" by Corneil, Olariu, and Stewart.

This recognition process performs six sweeps of lexicographical breadth first search (LBFS), including its variations such as LBFS+ and LBFS*.

Each sweep orders the graph's vertices, using previous sweep result(s) as a tiebreaking guide.

After the last sweep, the program checks whether this final sequence is umbrella-free.

If so, the input is an interval graph; otherwise, it is not

The paper shows the algorithm can run in linear time with respect to the size of the graph (number of vertices + number of edges).

However, the high level presentation in the paper, does not provide a direct path to a linear-time implementation.

Additionally, intermediate techniques such as partition refinement -- as often described in the literature --
lead to quadratic overall time due to repeated full scans through partitions.

To achieve linear-time performance, more efficient strategies must be (re)discovered to avoid costly operations and iterations.

Sophisticated data structures, and traversal patterns, are crucial to overcome computational bottlenecks.


Here in this program, I use partition tags for vertices in a way that eliminates many iterations during pivot selection in LBF*.

I also use doubly linked lists and pointers to manage partitions (slices) efficiently,
reducing the costs of vertex movements and partition updates (refinements).

In partition refinement, instead of going through partition by partition, and scanning all vertices,
I update the partitions by traversing only over the neighbors of the pivot vertex.


These optimizations contribute to faster execution times, although the program is not yet linear in the worst case.
Nevertheless, it is practical enough to process many large instances efficiently.


I have tried to keep my code simple and readable.

I also aim to remain faithful to the naming conventions and structures described in the aforementioned paper.

I test the program with small and big graphs, including both sparse and dense cases.
"""

# This is a helper class to represent each vertex of the input graph
# as a pointer object in a doubly linked list.

class Vertex_Pointer:
    """
    A node in a doubly linked list representing a vertex in the graph.

    Attributes:
        value (any): The label of the vertex.
        next (Vertex_Pointer or None): Reference to the next vertex in the list.
        prev (Vertex_Pointer or None): Reference to the previous vertex in the list.
    """
    def __init__(self, value):
        self.value = value
        self.next = None
        self.next = None

# This is a helper class, to represent each partition of vertex pointers in a doubly linked list.

class Partitions_Pointer:
    """
    Each partition maintains a list of vertices (as Vertex_Pointer objects), and pointers (prev and next)
    to adjacent partitions in the overall partition list.

    This data structure supports efficient insertion and removal of vertices.

    Attributes:
        next: Reference to the next partition in the partition list.
        prev: Reference to the previous part.
        head: The first vertex pointer in this partition.
        tail: The last vertex pointer in this partition.
        size: The number of vertices (or equivalently vertex pointers) currently in the partition.

    """
    def __init__(self):
        self.next = None
        self.prev = None

        self.head = None
        self.tail = None

        self.size = 0

    def add_v_pointer(self, vertex_ptr):
        """
        Adds a vertex pointer to the end (tail) of the partition.
        It runs in constant time.

        Input:
            vertex_ptr (Vertex_Pointer): The vertex pointer to be added.
        """
        self.size += 1

        if self.tail:
            self.tail.next = vertex_ptr
            vertex_ptr.prev = self.tail
            vertex_ptr.next = None
            self.tail = vertex_ptr

        else:
            vertex_ptr.prev = None
            vertex_ptr.next = None
            self.head = vertex_ptr
            self.tail = vertex_ptr

    def remove_v_pointer(self, vertex_ptr):
        """
        Removes a vertex pointer from the partition.
        It handles all cases:
         - vertex pointer is in the middle of the list
         - vertex pointer is at the tail or head
         - vertex is alone
        It runs in constant time.

        Input:
            vertex_ptr (Vertex_Pointer): The vertex pointer to be removed.
        """
        self.size -= 1

        if vertex_ptr.prev and vertex_ptr.next:
            vertex_ptr.prev.next = vertex_ptr.next
            vertex_ptr.next.prev = vertex_ptr.prev

        elif vertex_ptr.prev:
            vertex_ptr.prev.next = None
            self.tail = vertex_ptr.prev

        elif vertex_ptr.next:
            vertex_ptr.next.prev = None
            self.head = vertex_ptr.next

        else:
            self.head = self.tail = None

        vertex_ptr.prev = None
        vertex_ptr.next = None

def LBFS(graph):
    """
    This function computes a Lexicographic Breadth First Search (LBFS) ordering of
    the vertices of the given graph using partition refinement.

    Input:
        graph (dict): The graph represented as an adjacency list.
        order (list): A list of all vertices used to break ties.

    Output:
        list: A LBFS ordering of the vertices.

    """
    if not graph:
        return []


    vertex_to_pointer_map = {}
    initial_partition = Partitions_Pointer()
    partition_tag = {}

    for v in graph:
        v_ptr = Vertex_Pointer(v)
        vertex_to_pointer_map[v] = v_ptr
        initial_partition.add_v_pointer(v_ptr)
        partition_tag[v] = initial_partition

    partitions_head = initial_partition
    partitions_tail = initial_partition



    def partition_refinement(v):
        """
        This function, updates partitions based on neighbors of the pivot vertex 'v'.
        For each neighbor of v that is still in a partition:
        - move it to a new partition, before its current one.
        - then updates links and removes empty parts.

        """
        nonlocal partitions_head

        splitted = {}

        available_neighbors_of_pivot = []
        for neighbor in graph[v]:
            if neighbor in partition_tag:
                available_neighbors_of_pivot.append(neighbor)



        for neighbor in available_neighbors_of_pivot:

            part = partition_tag[neighbor]
            neighbor_ptr = vertex_to_pointer_map[neighbor]

            if part in splitted:
                v_neighbor_part = splitted[part]
            else:
                v_neighbor_part = Partitions_Pointer()
                splitted[part] = v_neighbor_part

                if partitions_head == part:
                    partitions_head = v_neighbor_part

                v_neighbor_part.next = part
                v_neighbor_part.prev = part.prev

                if part.prev:
                    part.prev.next = v_neighbor_part
                else:
                    partitions_head = v_neighbor_part

                v_neighbor_part.prev = part.prev
                part.prev = v_neighbor_part

            part.remove_v_pointer(neighbor_ptr)
            v_neighbor_part.add_v_pointer(neighbor_ptr)

            partition_tag[neighbor] = v_neighbor_part

            if part.size == 0:
                if part.prev:
                    part.prev.next = part.next
                if part.next:
                    part.next.prev = part.prev
                part.next = part.prev = None



    lbfs_order = []

    for _ in range(len(graph)):
        while partitions_head and partitions_head.head is None:
            partitions_head = partitions_head.next

        if not partitions_head:
            break

        pivot_ptr = partitions_head.head
        pivot_vertex = pivot_ptr.value
        lbfs_order.append(pivot_vertex)

        del partition_tag[pivot_vertex]

        partitions_head.remove_v_pointer(pivot_ptr)

        partition_refinement(pivot_vertex)

    return lbfs_order

def LBFS_plus(graph, order):
    """

    This function computes a Lexicographic Breadth First Search Plus (LBFS+) ordering of vertices in the input graph.

    LBFS+ is a variant of LBFS in which ties between equally prioritized vertices
    are broken by a tie-breaking order provided by the input list 'order'.

    To implement LBFS+ efficiently, the algorithm uses:
    - A partition refinement structure with doubly linked lists.
    - Vertex pointers for fast movement between partitions.
    - A partition_tag dictionary to track each vertex's current part / slice.

    Tie-breaking between neighbors of the pivot is done by sorting them based on the given order,
    which takes O(d log d) time per pivot with degree d. As a result, the overall time complexity is:

    O(m log n)

    inputs:
        graph (dict): Undirected graph represented as an adjacency list.
        order (list): A list of all vertices specifying the tie-breaking order.

    outputs:
        list: A vertex ordering produced by the LBFS+ algorithm.
    """

    if not graph:
        return []

    tie_breaking_position = {vertex: index for index, vertex in enumerate(order)}

    vertex_to_pointer_map = {}
    initial_partition = Partitions_Pointer()
    partition_tag = {}

    for v in order:
        v_ptr = Vertex_Pointer(v)
        vertex_to_pointer_map[v] = v_ptr
        initial_partition.add_v_pointer(v_ptr)
        partition_tag[v] = initial_partition

    partitions_head = initial_partition
    partitions_tail = initial_partition



    def partition_refinement(v):
        """
        This function, updates partitions based on the neighbors of the pivot vertex 'v'.
        Neighbors of v which are not yet transferred to the final LBFS plus order are
        considered one by one based on their position in the tie-breaking order.

        Thus this function sorts available neighbors of the input vertex based on their placement in the tie-breaking order.
        Then it moves each neighbor to "neighbor partition", newly placed immediately before its current one,
        and updates links and removes empty parts.

        It runs in O(d log d) time, where d is the degree of the pivot v, due to sorting by tie-break order.
        """

        nonlocal partitions_head

        splitted = {}

        available_neighbors_of_pivot = []
        for neighbor in graph[v]:
            if neighbor in partition_tag:
                available_neighbors_of_pivot.append(neighbor)

        available_neighbors_of_pivot.sort(key = lambda x:tie_breaking_position[x])


        for neighbor in available_neighbors_of_pivot:

            part = partition_tag[neighbor]
            neighbor_ptr = vertex_to_pointer_map[neighbor]

            if part in splitted:
                v_neighbor_part = splitted[part]
            else:
                v_neighbor_part = Partitions_Pointer()
                splitted[part] = v_neighbor_part

                if partitions_head == part:
                    partitions_head = v_neighbor_part

                v_neighbor_part.next = part
                v_neighbor_part.prev = part.prev

                if part.prev:
                    part.prev.next = v_neighbor_part
                else:
                    partitions_head = v_neighbor_part

                v_neighbor_part.prev = part.prev
                part.prev = v_neighbor_part

            part.remove_v_pointer(neighbor_ptr)
            v_neighbor_part.add_v_pointer(neighbor_ptr)

            partition_tag[neighbor] = v_neighbor_part

            if part.size == 0:
                if part.prev:
                    part.prev.next = part.next
                if part.next:
                    part.next.prev = part.prev
                part.next = part.prev = None



    lbfs_p_order = []

    for _ in range(len(graph)):
        while partitions_head and partitions_head.head is None:
            partitions_head = partitions_head.next

        if not partitions_head:
            break

        pivot_ptr = partitions_head.head
        pivot_vertex = pivot_ptr.value
        lbfs_p_order.append(pivot_vertex)

        del partition_tag[pivot_vertex]

        partitions_head.remove_v_pointer(pivot_ptr)

        partition_refinement(pivot_vertex)

    return lbfs_p_order

def LBFS_star(graph, order1, order2):
    """
    This function generates a Lexicographic Breadth First Search Star (LBFS*) order of the vertices of the input graph.

    This function performs partition refinement on doubly-linked lists and uses vertex pointers.
    Nested helper functions will handle pivot selection, vertex status checks, and partition
    updates based on two input tie-breaking orderings.

    inputs:
        graph (dict): An undirected graph as an adjacency list.
        order1 (list): The first tie-breaking order of vertices.
        order2 (list): The second tie-breaking order of vertices.

    outputs:
        list: The LBFS* ordering of vertices.

    Time Complexity:
    The overall time complexity of this specific implementation in the worst case is **not linear-time**.
    It is super-linear due to the following bottlenecks:
    - The "status" helper function computes a vertex's status by examining
      all of its neighbors and (possibly) all of their neighbors as well.
      This can be very costly.
    - The 'last_vertex' helper function performs a linear scan through a
      partition to find the last vertex, in each scan which makes the running time slow for large partitions.

    """


    if not graph:
        return []

    tie_breaking_pos1 = {vertex: index for index, vertex in enumerate(order1)}
    tie_breaking_pos2 = {vertex: index for index, vertex in enumerate(order2)}

    vertex_to_pointer_map = {}
    initial_partition = Partitions_Pointer()
    partition_tag = {}

    for v in order1:
        v_ptr = Vertex_Pointer(v)
        vertex_to_pointer_map[v] = v_ptr
        initial_partition.add_v_pointer(v_ptr)
        partition_tag[v] = initial_partition

    partitions_head = initial_partition



    def last_vertex(slice_S, ordering):
        """
        This function returns a pointer to the vertex in the given partition slice that
        appears last in the specified ordering.

        Input:
            slice_S: A partition (doubly linked list of vertex pointers).
            ordering (dict): Maps each vertex to its index in the overall ordering.

        Output:
            A pointer to the vertex with the highest/max index in the ordering, or None if empty.
        """

        if not slice_S:
            return None

        last_vertex_ptr = None
        last_index = -1
        v_ptr = slice_S.head

        while v_ptr:
            if  last_index < ordering[v_ptr.value]:
                last_index = ordering[v_ptr.value]
                last_vertex_ptr = v_ptr
            v_ptr = v_ptr.next

        return last_vertex_ptr




    def status(current_slice, vertex_ptr):
        """
        It determines the status ("F", "NF", or "OK") of the vertex represented by vertex_ptr within its current slice.
        This status is critical for selecting the correct pivot in the LBFS* algorithm.

        Status definitions:
        - "F"  (flies): The vertex has a one neighbor outside the current slice.
        - "NF" (neighbor-fly): The vertex has no neighbors outside the current slice,
                               but has a neighbor that itself has a neighbor outside the current slice.
        - "OK": The vertex is neither "F" nor "NF".

        The use of partition_tag significantly reduces the computational costs of this check, and speeds up the running time.
        However, this function remains a bottleneck and prevents the overall algorithm from achieving strict linearity in the worst case.

        Time Complexity:
            O(deg(v) + sum(deg(u))) â€” where deg(v) is the degree of the vertex,
            and the sum is over the degrees of its neighbors (needed for the "NF" check).

        Inputs:
             current_slice (Partitions_Pointer): The partition slice to which the vertex belongs.
            vertex_ptr (Vertex_Pointer): Pointer to the vertex being evaluated.

        Output:
            str: One of "F", "NF", or "OK" indicating the vertex's status.
        """

        v = vertex_ptr.value
        neighbors_v = graph[v]

        for u in neighbors_v:
            if u in partition_tag and partition_tag[u] != current_slice:
                return "F"

        for u in neighbors_v:
            if u in partition_tag and partition_tag[u] == current_slice:
                neighbors_u = graph[u]
                for u_u in neighbors_u:
                    if u_u in partition_tag and partition_tag[u_u] != current_slice:
                        return "NF"

        return "OK"



    def pivot(current_slice, ordering1, ordering2):
        """
        This function chooses a pivot vertex from the current slice based on status and two orderings.

        The function first identifies two candidate pivots:
        alpha, the last vertex in current_slice according to ordering1,
        and beta, the last vertex according to ordering2.

        It then compares their computed statuses and
        selects a pivot based on the following priority rules (in the code bellow).

        Input:
            current_slice: A partition (linked list of vertex pointers).
            ordering1, ordering2 (dict): Two orderings vertices to their position.

        Output:
            The chosen pivot vertex pointer based on status priority rules.
        """

        alpha = last_vertex(current_slice, ordering1)
        beta  = last_vertex(current_slice, ordering2)

        if not alpha:
            return beta
        if not beta:
            return alpha


        alpha_status = status(current_slice, alpha)
        beta_status  = status(current_slice, beta)

        if alpha_status  == "F":
            return beta
        elif beta_status == "F":
            return alpha
        elif alpha_status == "NF":
            return beta
        elif beta_status  == "NF":
            return alpha
        else:
            return beta


    def partition_refinement(v):
        """
        This function updates partitions based on the neighbors of vertex 'v'.

        - Moves each neighbor to a new partition before its current one, preserving LexBFS ordering.
        - Updates links and removes empty parts.

        """
        nonlocal partitions_head

        splitted = {}

        available_neighbors_of_pivot = []
        for neighbor in graph[v]:
            if neighbor in partition_tag:
                available_neighbors_of_pivot.append(neighbor)


        for neighbor in available_neighbors_of_pivot:

            part = partition_tag[neighbor]
            neighbor_ptr = vertex_to_pointer_map[neighbor]

            if part in splitted:
                v_neighbor_part = splitted[part]
            else:
                v_neighbor_part = Partitions_Pointer()
                splitted[part] = v_neighbor_part

                if partitions_head == part:
                    partitions_head = v_neighbor_part

                v_neighbor_part.next = part
                v_neighbor_part.prev = part.prev

                if part.prev:
                    part.prev.next = v_neighbor_part
                else:
                    partitions_head = v_neighbor_part

                v_neighbor_part.prev = part.prev
                part.prev = v_neighbor_part

            part.remove_v_pointer(neighbor_ptr)
            v_neighbor_part.add_v_pointer(neighbor_ptr)

            partition_tag[neighbor] = v_neighbor_part

            if part.size == 0:
                if part.prev:
                    part.prev.next = part.next
                if part.next:
                    part.next.prev = part.prev
                part.next = part.prev = None



    final_order = []

    for _ in range(len(graph)):
        while partitions_head and partitions_head.head is None:
            partitions_head = partitions_head.next

        if not partitions_head:
            break

        current_slice = partitions_head
        pivot_vertex_ptr = pivot(current_slice, tie_breaking_pos1, tie_breaking_pos2)
        pivot_vertex = pivot_vertex_ptr.value
        final_order.append(pivot_vertex)

        pivot_ptr = vertex_to_pointer_map[pivot_vertex]
        current_partition = partition_tag[pivot_vertex]

        current_partition.remove_v_pointer(pivot_ptr)
        del partition_tag[pivot_vertex]

        partition_refinement(pivot_vertex)

    return final_order

def is_interval(graph):
    """
    This functin determines if the input graph is an interval graph using six sweeps of LBFS, LBFS+ and LBFS*,
    and checks if the final sweep is umbrella-free.

    Pre-calculations like computing the rightmost neighbor and set of forward neighbors
    for each vertex, based on the last order, speed up the execution significantly.
    (Although it may trade space for time in large cases.)

    input:
        graph (dict): Adjacency list representation of the graph.

    output:
        bool: True if the graph is an interval graph, False otherwise.

    """


    if not graph:
        return False

    pi = LBFS(graph)
    rev_pi = list(reversed(pi))

    pi_prime = LBFS_plus(graph, rev_pi)
    rev_pi_prime = list(reversed(pi_prime))

    sigma = LBFS_plus(graph, rev_pi_prime)
    rev_sigma = list(reversed(sigma))

    sigma_plus = LBFS_plus(graph, rev_sigma)
    rev_sigma_plus = list(reversed(sigma_plus))

    sigma_plus_plus = LBFS_plus(graph, rev_sigma_plus)

    sigma_star = LBFS_star(graph, sigma_plus, sigma_plus_plus)



    pos = {vertex: index for index, vertex in enumerate(sigma_star)}
    n = len(sigma_star)


    rightmost_neighbor = [-1] * n
    for vertex in graph:
        v_index = pos[vertex]
        right = v_index
        for neighbor in graph[vertex]:
            right = max(right, pos[neighbor])
        rightmost_neighbor[v_index] = right


    is_neighbor = [set() for _ in range(n)]
    for vertex in graph:
        v_index = pos[vertex]
        for neighbor in graph[vertex]:
            is_neighbor[v_index].add(pos[neighbor])


    for i in range(n):
        r = rightmost_neighbor[i]
        if r <= i:
            continue

        neighbors = is_neighbor[i]
        for j in range(i + 1, r):
            if j not in neighbors:
                return False

    return True

"""# **Sample Tests**

## **Small Samples**
"""

c3 = {1: [2, 3], 2: [1, 3], 3: [1, 2]}
is_interval(c3)

c4 = {'x': ['y', 'w'], 'y': ['x', 'z'], 'z': ['y', 'w'], 'w': ['z', 'x']}
is_interval(c4)

k4 = {'A': ['B', 'C', 'D'], 'B': ['A', 'C', 'D'], 'C': ['A', 'B', 'D'], 'D': ['A', 'B', 'C']}
is_interval(k4)

astroidal_triple = {
    'v0': ['v1', 'v3', 'v5'],
    'v1': ['v0', 'v2'],
    'v2': ['v1'],
    'v3': ['v0', 'v4'],
    'v4': ['v3'],
    'v5': ['v0', 'v6'],
    'v6': ['v5'] }

is_interval(astroidal_triple)

# Graph representation as dictionary of adjacency lists of FIG. 15.
# (also fig 7) in the main Article:
#  https://webdocs.cs.ualberta.ca/~stewart/Pubs/IntervalSIAM.pdf


fig7 = {1: [2],
        2: [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],
        3: [2, 4],
        4: [2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22],
        5: [2, 4, 6],
        6: [2, 4, 5, 7, 8],
        7: [2, 4, 6, 8, 9],
        8: [2, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],
        9: [2, 4, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18],
        10: [2, 4, 8, 9, 11],
        11: [2, 4, 8, 9, 10, 12, 13],
        12: [2, 4, 8, 9, 11, 13, 14, 15, 16, 17],
        13: [2, 4, 8, 9, 11, 12, 14, 15],
        14: [2, 4, 8, 9, 12, 13],
        15: [2, 4, 8, 9, 12, 13, 16],
        16: [2, 4, 8, 9, 12, 15],
        17: [2, 4, 8, 9, 12, 18],
        18: [2, 4, 8, 9, 17, 19],
        19: [2, 4, 8, 18],
        20: [2, 4, 8, 21],
        21: [4, 20],
        22: [4]  }

is_interval(fig7)

# Graph representation as dictionary of adjacency lists of FIG. 1. in the main Article:
#  https://webdocs.cs.ualberta.ca/~stewart/Pubs/IntervalSIAM.pdf

fig1 = {1: [2, 3],
        2: [1, 3, 4, 5, 6, 7, 8, 9, 10],
        3: [1, 2, 4],
        4: [2, 3, 5, 6, 7, 8, 9, 10],
        5: [6, 2, 4],
        6: [5, 7, 8, 9, 11, 2, 4],
        7: [6, 8, 2, 4],
        8: [6, 7, 9, 10, 2, 4],
        9: [6, 8, 2, 4],
        10: [8, 2, 4],
        11: [6]
        }
is_interval(fig1)

# FIG. 3. in the main Article.

fig3 = {1: [4, 3, 2],
        2: [1, 3, 5],
        3: [4, 1, 2, 5],
        4: [3, 1],
        5: [3, 2]}

is_interval(fig3)

# FIG. 4. in the main Article

fig4 = {1: [2, 3, 4],
        2: [1, 3, 5],
        3: [2, 1, 4],
        4: [1, 3, 5],
        5: [2, 4]}

is_interval(fig4)

# FIG. 5. left figure in the main Article

fig5a = {1: [2, 3, 4, 'z'],
         2: [1, 3, 'y'],
         3: ['y', 2, 1, 4, 'x'],
         4: [1, 3, 'z', 'x'],
         'y': [2, 3],
         'x': [3, 4],
         'z': [1, 4]}

is_interval(fig5a)

# FIG. 5. right one in the main Article

fig5b = {1: [2, 3, 'z'],
         2: [1, 'y', 3],
         3: ['y', 2, 1, 'x'],
         'x': [3, 'z'],
         'y': [2, 3],
         'z': [1, 'x']}

is_interval(fig5b)

trapezoid_graph = {
    1: [2, 4, 6],
    2: [1, 3, 4],
    3: [2, 4, 6, 7],
    4: [1, 2, 3, 5, 6],
    5: [4, 6, 7],
    6: [1, 3, 4, 5, 7],
    7: [3, 5, 6]
}

is_interval(trapezoid_graph)

# A circular interval graph

cir = {1: [2, 6, 8],
       2: [1, 3],
       3: [2, 4],
       4: [3, 5],
       5: [4, 6],
       6: [1, 5, 7],
       7: [6],
       8: [1]}

is_interval(cir)

# The picture on "Interval graph" entry in Wikipedia

graph_wiki = {'A': ['B', 'C', 'D'],
              'B': ['A', 'C'],
              'C': ['B', 'A', 'D', 'F', 'E'],
              'D': ['A', 'C', 'E', 'F'],
              'E': ['C', 'D'],
              'F': ['D', 'C', 'G'],
              'G': ['F']}

is_interval(graph_wiki)

# Graph representation of FIG. 1. in the following paper:
#  A Four-Sweep LBFS Recognition Algorithm for Interval Graph

Tze_Heng_graph = {
0: [1],
1: [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],
2: [1, 3],
3: [1, 2, 4, 5],
4: [1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],
5: [1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13],
6: [1, 4, 5, 7],
7: [1, 4, 5, 6, 8, 9],
8: [1, 4, 5, 7, 9, 10, 11, 12, 13],
9: [1, 4, 5, 7, 8, 10, 11],
10: [1, 4, 5, 8, 9, 11],
11: [1, 4, 5, 8, 9, 10, 12],
12: [1, 4, 5, 8, 11],
13: [1, 4, 5, 8, 14],
14: [1, 4, 13],
15: [1, 4, 16],
16: [15]
}

is_interval(Tze_Heng_graph)

"""## **Big Samples**

Here, I test the correctness and performance of the program using sparse graph structures,
which are known to belong to the class of interval graphs.

For each sample, the output shows
whether the graph is an interval graph (True/False),
the number of vertices and
number of edges,
their sum as graph size, and
the time taken by is_interval() in seconds.

This time **does not include** the **graph construction time**.
"""

def path(n):
    """
    It generates a path of n vertices.
    This graph has n-1 edges.
    Each path graph is clearly an interval graph.
    """
    graph = {v: [v-1, v+1] for v in range(2, n)}
    graph[1] = [2]
    graph[n] = [n-1]
    return graph

import time

def interval_graph_test_path(n):
    """
    Generates a path graph with n vertices, runs the is_interval function on it,
    and prints a summary table including:

    - Whether the graph is interval
    - Number of vertices
    - Number of edges
    - Size of the graph (vertices + edges)
    - Execution time of the   is_interval   function in seconds

    Input:
        n (int): Number of vertices in the Feder graph.
    """

    graph = path(n)

    num_vertices = n
    num_edges = n - 1
    graph_size = num_vertices + num_edges

    start = time.time()
    result = is_interval(graph)
    finish = time.time()
    running_time = finish - start

    # Print table
    print(f"\n{'Is Interval':<12} {'Vertices':<12} {'Edges':<12} {'Size':<12} {'Time (s)':<10}")
    print(f"{'-'*60}")
    print(f"{str(result):<12} {num_vertices:<12} {num_edges:<12} {graph_size:<12} {running_time:.6f}")

interval_graph_test_path(10**3)

interval_graph_test_path(10**4)

interval_graph_test_path(10**5)

interval_graph_test_path(10**6)

interval_graph_test_path(10**7)

def Feder_graph(n):
    """
    It genrates a graph with n vertices and 2*n-5 edges.
    This graph consists of a path of n-1 vertices, and an additional vertex connected to all vertices of this path but the first and last ones.
    """
    graph = {}
    graph[1] = [vertex for vertex in range(3, n)]
    graph[2] = [3]
    graph[n] = [n-1]
    for v in range(3, n):
        graph[v] = [1, v-1, v+1]

    return graph

import time

def interval_graph_test_Feder_graph(n):
    """
    Generates a Feder graph with n vertices, runs the is_interval function on it,
    and prints a summary table including:

    - Whether the graph is interval
    - Number of vertices
    - Number of edges
    - Size of the graph (vertices + edges)
    - Execution time of the   is_interval   function in seconds

    Input:
        n (int): Number of vertices in the Feder graph.
    """

    graph = Feder_graph(n)

    num_vertices = n
    num_edges = 2 * n - 5
    graph_size = num_vertices + num_edges

    start = time.time()
    result = is_interval(graph)
    finish = time.time()
    running_time = finish - start

    # Print table
    print(f"\n{'Is Interval':<12} {'Vertices':<12} {'Edges':<12} {'Size':<12} {'Time (s)':<10}")
    print(f"{'-'*60}")
    print(f"{str(result):<12} {num_vertices:<12} {num_edges:<12} {graph_size:<12} {running_time:.6f}")

interval_graph_test_Feder_graph(10**3)

interval_graph_test_Feder_graph(10**4)

interval_graph_test_Feder_graph(10**5)

interval_graph_test_Feder_graph(10**6)

interval_graph_test_Feder_graph(2*10**6)

"""## **Big Samples**

I test the correctness and performance of the program using complete graphs, which are the densest type of graph.

Complete graphs are obviously interval graphs.

For each sample, the output shows
whether the graph is an interval graph (True/False),
the number of vertices and
number of edges,
their sum as graph size, and
the time taken by is_interval() in seconds. This time **does not include** the graph **construction time**.
"""

import networkx
import time

def interval_graph_test_complete(n):
    """
    Generates a complete graph with n vertices, runs the is_interval function on it,
    and prints a summary table including:

    - Whether the graph is interval
    - Number of vertices
    - Number of edges
    - Size of the graph (vertices + edges)
    - Execution time of the   is_interval   function in seconds

    Input:
        n (int): Number of verices.
    """

    K = networkx.complete_graph(n)
    K_valid_format = {node: list(K[node]) for node in K.nodes()}
    num_vertices = K.number_of_nodes()
    num_edges = K.number_of_edges()
    graph_size = num_vertices + num_edges

    start = time.time()
    result = is_interval(K_valid_format)
    finish = time.time()
    running_time = finish - start

    # Print table
    print(f"\n{'Is Interval':<12} {'Vertices':<12} {'Edges':<12} {'Size':<12} {'Time (s)':<10}")
    print(f"{'-'*60}")
    print(f"{str(result):<12} {num_vertices:<12} {num_edges:<12} {graph_size:<12} {running_time:.6f}")

interval_graph_test_complete(100)

interval_graph_test_complete(500)

interval_graph_test_complete(1000)

interval_graph_test_complete(1500)

# interval_graph_test_complete(1420)

# interval_graph_test_complete(4490)

"""## **Big Samples**

I test the correctness and performance of the program using Mycielski graphs,
which lie between sparse and dense graphs in terms of edge density.

Since Mycielski graphs are not chordal, they are not interval either.

The time shown in the output does not include the graph construction time.
"""

from networkx.generators.mycielski import mycielski_graph
import time

def interval_graph_test_Mycielski(n):
    """
    Generates a Mycielski graph with n vertices, runs the is_interval function on it,
    and prints a summary table including:

    - Whether the graph is interval
    - Number of vertices
    - Number of edges
    - Size of the graph (vertices + edges)
    - Execution time of the  is_interval function in seconds

    Input:
        n (int): Number of levels the Mycielski operation is performed.
    """

    M = mycielski_graph(n)
    M_valid_format = {node: list(M[node]) for node in M.nodes()}
    num_vertices = M.number_of_nodes()
    num_edges = M.number_of_edges()
    graph_size = num_vertices + num_edges

    start = time.time()
    result = is_interval(M_valid_format)
    finish = time.time()
    running_time = finish - start

    # Print table
    print(f"\n{'Is Interval':<12} {'Vertices':<12} {'Edges':<12} {'Size':<12} {'Time (s)':<10}")
    print(f"{'-'*60}")
    print(f"{str(result):<12} {num_vertices:<12} {num_edges:<12} {graph_size:<12} {running_time:.6f}")

interval_graph_test_Mycielski(12)

interval_graph_test_Mycielski(13)

interval_graph_test_Mycielski(14)

interval_graph_test_Mycielski(15)